{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ekpenyong-Esu/Deep-RL-Exercise/blob/main/continous_Q_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "21euteRCVpZf"
      },
      "outputs": [],
      "source": [
        "\n",
        "#!pip3 install pyvirtualdisplay\n",
        "#!pip install gym[classic_control]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kFyfoWod299q"
      },
      "outputs": [],
      "source": [
        "#!apt update && apt install xvfb\n",
        "#!pip install gym-notebook-wrapper\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qTVURIki3Oww"
      },
      "outputs": [],
      "source": [
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Kls2ahOoVfPz"
      },
      "outputs": [],
      "source": [
        "%matplotlib notebook\n",
        "\n",
        "import time  # slow the game down a little bit\n",
        "#from pyglet.window import key  # for manual playing\n",
        "\n",
        "import gym\n",
        "import numpy as np  # used for all kinds of matrix / vector operations\n",
        "import matplotlib.pyplot as plt  # for plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "gLl672-zY02M"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20000\n",
        "ALPHA = 0.8\n",
        "GAMMA = 0.9\n",
        "\n",
        "\n",
        "NUM_BINS = 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\""
      ],
      "metadata": {
        "id": "3MuRTsLY1yr1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "n0ApV_jFY5Kp"
      },
      "outputs": [],
      "source": [
        "# Exploration vs. Exploitation parameters\n",
        "#epsilon = 1.0                 # Exploration rate\n",
        "#max_epsilon = 1.0             # Exploration probability at start\n",
        "#min_epsilon = 0.01            # Minimum exploration probability \n",
        "#decay_rate = 0.001             # Exponential decay rate for exploration prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "-NEi4XZIX2u4"
      },
      "outputs": [],
      "source": [
        "env = gym.make('CartPole-v1') # We want to solve the CartPole task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsA4BxplX84G"
      },
      "source": [
        "Let us take a look at the possible actions.\n",
        "You can find them here: https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py\n",
        "As we can see, there are 4 observations:\n",
        "* Cart Position (-4.8 to 4.8)\n",
        "* Cart Velocity $(-\\infty \\text{ to } \\infty)$\n",
        "* Pole Angle (-0.418 to 0.418) rad or (-24 to 24) degrees\n",
        "* Pole Angular Velocity $(-\\infty \\text{ to } \\infty)$\n",
        "\n",
        "and two actions:\n",
        "* 0 - Move to the left\n",
        "* 1 - Move to the right\n",
        "\n",
        "The next cell contains code to play the game manually - Feel free to try it out by using the left and right arrow key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Kf7Hf9myX45V"
      },
      "outputs": [],
      "source": [
        "# Digitization\n",
        "\n",
        "def create_bins(num_bins_per_action=10):\n",
        "  bins_cart_position = np.linspace(-4.8, 4.8, num_bins_per_action)  # bins for the cart position\n",
        "  bins_cart_velocity = np.linspace(-5, 5, num_bins_per_action)  # bins for the cart velocity\n",
        "  bins_pole_angle = np.linspace(-0.418, 0.418, num_bins_per_action)  # bins for the pole angle\n",
        "  bins_pole_angular_velocity = np.linspace(-5, 5, num_bins_per_action)  # bins for the pole angular velocity\n",
        "  bins = np.array([bins_cart_position, bins_cart_velocity, bins_pole_angle, bins_pole_angular_velocity])  # merge them\n",
        "  return bins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "bswD6AeZYUl6"
      },
      "outputs": [],
      "source": [
        "# digitization continues \n",
        "def discretize_observation(observations, bins):\n",
        "    binned_observations = []\n",
        "    for i, observation in enumerate(observations):\n",
        "        discretized_observation = np.digitize(observation, bins[i])\n",
        "        binned_observations.append(discretized_observation)\n",
        "    return tuple(binned_observations) # Important for later indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBxHRElLgXLE",
        "outputId": "0748dcee-68d5-4e22-d19f-371241d9cba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 10, 10, 10, 2)\n"
          ]
        }
      ],
      "source": [
        "q_table_shape = (NUM_BINS, NUM_BINS, NUM_BINS, NUM_BINS, env.action_space.n)\n",
        "q_table = np.zeros(q_table_shape)\n",
        "print(q_table.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "EZyUf5whcths"
      },
      "outputs": [],
      "source": [
        "#Epsilon greedy function \n",
        "def epsilon_greedy_action_selection(epsilon, q_table, discrete_state):\n",
        "    '''\n",
        "    Returns an action for the agent. Note how it uses a random number to decide on\n",
        "    exploration versus explotation trade-off.\n",
        "    '''\n",
        "    random_number = np.random.random()\n",
        "    \n",
        "    # EXPLOITATION, USE BEST Q(s,a) Value\n",
        "    if random_number > epsilon:\n",
        "\n",
        "        action = np.argmax(q_table[discrete_state]) #This take all the four eleme\n",
        "                                                    #nts and take The index of the \n",
        "                                                    #largest element \n",
        "\n",
        "    # EXPLORATION, USE A RANDOM ACTION\n",
        "    else:\n",
        "        # Return a random 0,1,2,3 action\n",
        "        action = np.random.randint(0, env.action_space.n)\n",
        "\n",
        "    return action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "TK7x9deWg859"
      },
      "outputs": [],
      "source": [
        "#Belman equation\n",
        "def compute_next_q_value(old_q_value, reward, next_optimal_q_value):\n",
        "    \n",
        "    return old_q_value +  ALPHA * (reward + GAMMA * next_optimal_q_value - old_q_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1yrJQmQgmnf6"
      },
      "outputs": [],
      "source": [
        "\n",
        "BINS = create_bins(NUM_BINS)  # Create the bins used for the rest of the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "VgYtubJshCKO"
      },
      "outputs": [],
      "source": [
        "#We are going use a burn in linear reduction of epsilon\n",
        "\n",
        "BURN_IN = 1\n",
        "epsilon = 1\n",
        "\n",
        "EPSILON_END= 10000\n",
        "EPSILON_REDUCE = 0.0001\n",
        "\n",
        "\n",
        "\n",
        "def reduce_epsilon(epsilon, epoch):\n",
        "    if BURN_IN <= epoch <= EPSILON_END:\n",
        "        epsilon-= EPSILON_REDUCE\n",
        "    return epsilon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "B-dCIHUwkXAk"
      },
      "outputs": [],
      "source": [
        "# We create our custom reward\n",
        "\n",
        "def fail(done, points, reward):\n",
        "    if done and points < 150:\n",
        "        reward = -200\n",
        "    return reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "-3DSB6OLlnD0",
        "outputId": "0d31c5e4-1948-4336-fed9-90b9d3f42f71"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=600x400 at 0x7FD39097BCD0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    ## Continuous State --> Discrete State\n",
        "    \n",
        "    initial_state = env.reset()  # get the initial observation\n",
        "    discretized_state = discretize_observation(initial_state, BINS)  # map the observation to the bins\n",
        "    \n",
        "    done = False  # to stop current run when cartpole falls down   \n",
        "    points = 0  # store result\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    while not done:  # Perform current run as long as done is False (as long as the cartpole is up)\n",
        "        \n",
        "       \n",
        "        env.render()\n",
        "        display.clear_output(wait=True)\n",
        "        frame = env.render(mode='rgb_array')\n",
        "        cv2_imshow(frame)\n",
        "        cv2.waitKey(1)\n",
        "        \n",
        "       \n",
        "\n",
        "        print(f\"EPOCH is {epoch}: \")\n",
        "\n",
        "        action = epsilon_greedy_action_selection(epsilon, q_table, discretized_state)  # Epsilon-Greedy Action Selection \n",
        "        next_state, reward, done, info = env.step(action)  # perform action and get next state\n",
        "        reward = fail(done, points, reward)  # Check if reward or fail state\n",
        "\n",
        "\n",
        "        next_state_discretized = discretize_observation(next_state, BINS)  # map the next observation to the bins\n",
        "\n",
        "        old_q_value =  q_table[discretized_state + (action,)]  # get the old Q-Value from the Q-Table\n",
        "        next_optimal_q_value = np.max(q_table[next_state_discretized])  # Get the next optimal Q-Value\n",
        "        \n",
        "\n",
        "        next_q = compute_next_q_value(old_q_value, reward, next_optimal_q_value)  # Compute next Q-Value\n",
        "        q_table[discretized_state + (action,)] = next_q  # Insert next Q-Value into the table\n",
        "\n",
        "        discretized_state = next_state_discretized  # Update the old state\n",
        "        points += 1\n",
        "\n",
        "    epsilon = reduce_epsilon(epsilon, epoch)  # Reduce epsilon\n",
        "    \n",
        "    \n",
        "env.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "observation = env.reset()\n",
        "rewards = 0\n",
        "for _ in range(1000):\n",
        "    env.render()\n",
        "    discrete_state = discretize_observation(observation, BINS)  # get bins\n",
        "    action = np.argmax(q_table[discrete_state])  # and chose action from the Q-Table\n",
        "    observation, reward, done, info = env.step(action) # Finally perform the action\n",
        "    rewards+=1\n",
        "    if done:\n",
        "        print(f\"You got {rewards} points!\")\n",
        "        break\n",
        "env.close()\n"
      ],
      "metadata": {
        "id": "u3jUzZTL6YG4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3xovjhhSAgcCLFvjSZIyN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}