{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzkhbqEBnzmUC1XGG8Ekxk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!sudo apt-get install xvfb\n",
        "\n",
        "#!pip install gym[classic_control]"
      ],
      "metadata": {
        "id": "WpQ24iqMBqEX"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install gym-notebook-wrapper"
      ],
      "metadata": {
        "id": "Oqcw4R4ymo5w"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gnwrapper"
      ],
      "metadata": {
        "id": "F3aGdxin-nwn"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "4adpcPUiO9vF"
      },
      "outputs": [],
      "source": [
        "#Importing libraries\n",
        "import gym\n",
        "from collections import namedtuple\n",
        "import numpy as np\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 16\n",
        "PERCENTILE = 70\n"
      ],
      "metadata": {
        "id": "UpOr9GtKPWiR"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the nn Class\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, obs_size, hidden_size, n_actions):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(obs_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, n_actions)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ],
      "metadata": {
        "id": "hIV-IigKm3oA"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using name tupple\n",
        "Episode = namedtuple('Episode', field_names=['reward', 'steps'])\n",
        "EpisodeStep = namedtuple('EpisodeStep', field_names=['observation', 'action'])"
      ],
      "metadata": {
        "id": "3s7oZVCym__b"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use to iterate batches\n",
        "def iterate_batches(env, net, batch_size):\n",
        "    batch = []\n",
        "    episode_reward = 0.0\n",
        "    episode_steps = []\n",
        "    obs = env.reset()      # Reseting the environment to get the current state of the environment\n",
        "    sm = nn.Softmax(dim=1) # Pass it a softmax activation function with dimention of 1\n",
        "    while True:\n",
        "        obs_v = torch.FloatTensor([obs])  # Change the current state to tensor float of 1 x4 since the enironment have 4 environment space\n",
        "        act_probs_v = sm(net(obs_v))      # This returns tensors that tracks Gradient\n",
        "        act_probs = act_probs_v.data.numpy()[0] # We use this to unpack the tensor and only return the first dimension [0] using the .data\n",
        "                                                # and then converting it to numpy array\n",
        "        action = np.random.choice(len(act_probs), p=act_probs) # The action is take by using numpy sampling choice base on the return obs space value\n",
        "        next_obs, reward, is_done, _ = env.step(action)       # Take the action and return the current state of the environment\n",
        "        episode_reward += reward\n",
        "        step = EpisodeStep(observation=obs, action=action)  # assign the environment gotten from line 5 to the name tuple which is as a list or class\n",
        "        episode_steps.append(step)                        # append the step to eppisode_steps\n",
        "        if is_done:\n",
        "            e = Episode(reward=episode_reward, steps=episode_steps) # if the game is done assign the episode reward and action the the episode name tuple\n",
        "            batch.append(e)                                   # append the result to the batch\n",
        "            episode_reward = 0.0                              # clear the the episode reward\n",
        "            episode_steps = []                                # Clear the episode step\n",
        "            next_obs = env.reset()                            # Reset the environment for new state\n",
        "            if len(batch) == batch_size:                      # If The game is finish\n",
        "                yield batch                                   #Yield return contro to the caller\n",
        "                batch = []                                    #Clear the batch\n",
        "        obs = next_obs                                      # assigned the environment we got from  line 13\n"
      ],
      "metadata": {
        "id": "9Vnc-9HXoQS4"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filter batches\n",
        "\n",
        "def filter_batch(batch, percentile):\n",
        "    rewards = list(map(lambda s: s.reward, batch))  # map the batch to the lamda function and return only the reward\n",
        "    reward_bound = np.percentile(rewards, percentile) # calculate the array of the reward as for 70 percentile reward bound\n",
        "    reward_mean = float(np.mean(rewards))            # calculate the mean of the reward and convert it to numpy array\n",
        "\n",
        "    train_obs = []\n",
        "    train_act = []\n",
        "    for reward, steps in batch:        \n",
        "        if reward < reward_bound:                   # If reward is below 70 percentile\n",
        "            continue                                # continue\n",
        "        train_obs.extend(map(lambda step: step.observation, steps))  # Return observation using map function\n",
        "        train_act.extend(map(lambda step: step.action, steps))        # return action \n",
        "\n",
        "    train_obs_v = torch.FloatTensor(train_obs)               #Convert the train observation to tensor float\n",
        "    train_act_v = torch.LongTensor(train_act)               # convert action to to tensor Long\n",
        "    return train_obs_v, train_act_v, reward_bound, reward_mean"
      ],
      "metadata": {
        "id": "_47yom9i2mNb"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    #env = gym.make(\"CartPole-v0\")\n",
        "    env = gnwrapper.Animation(gym.make('CartPole-v1'))     #Make the Environment\n",
        "    #env = gym.wrappers.Monitor(env, directory=\"mon\", force=True)\n",
        "    obs_size = env.observation_space.shape[0]   # here we return the environment size\n",
        "    n_actions = env.action_space.n              # This returns the number of possible action in a gym env observation\n",
        "\n",
        "    net = Net(obs_size, HIDDEN_SIZE, n_actions)   # We apply our net Class here with obs_size=4, n_ction= 2\n",
        "    objective = nn.CrossEntropyLoss()             # We use our cross entropy loss optimixer to reduce the error\n",
        "    optimizer = optim.Adam(params=net.parameters(), lr=0.01) #We use adam as the optimizer\n",
        "    writer = SummaryWriter(comment=\"-cartpole\")         # For tensor board\n",
        "\n",
        "    for iter_no, batch in enumerate(iterate_batches(\n",
        "            env, net, BATCH_SIZE)):\n",
        "        obs_v, acts_v, reward_b, reward_m = \\\n",
        "            filter_batch(batch, PERCENTILE)\n",
        "        optimizer.zero_grad()\n",
        "        action_scores_v = net(obs_v)\n",
        "        loss_v = objective(action_scores_v, acts_v)\n",
        "        loss_v.backward()\n",
        "        optimizer.step()\n",
        "        env.render()\n",
        "        print(\"%d: loss=%.3f, reward_mean=%.1f, rw_bound=%.1f\" % (\n",
        "            iter_no, loss_v.item(), reward_m, reward_b))\n",
        "        writer.add_scalar(\"loss\", loss_v.item(), iter_no)\n",
        "        writer.add_scalar(\"reward_bound\", reward_b, iter_no)\n",
        "        writer.add_scalar(\"reward_mean\", reward_m, iter_no)\n",
        "        if reward_m > 300:\n",
        "            print(\"Solved!\")\n",
        "            break\n",
        "    writer.close()\n",
        "    env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "_vX5E8FH9NHt",
        "outputId": "c66a39b1-907e-490e-df5c-335aa2c6e4b0"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45: loss=0.570, reward_mean=308.9, rw_bound=349.0\n",
            "Solved!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}